\section{Discussion}
Figure \ref{fig:Searchtimefulltext10} illustrates that Index 10.0, 10.1 and 10.2 all search in linear time. Index 10.2 is guaranteed to run in linear time due to the Apostolico-Giancarlo extension. It is however also this index that performs the slowest compared to the others. This may simply be because Index10.2 has more logic to consider, to guarantee that the algorithm runs in linear time. The problems and worst case queries and search text for the Boyer-Moore Algorithm, that Apostolico-Giancarlo manage to handle in linear time are however not that common in natural English languish. When testing Apostolico-Giancarlo up against Boyer-Moore on natural languish, Apostolico-Giancarlo simply turn out to be a slower version of the Boyer-Moore algorithm. In order to see the a positive difference where the Apostolico-Giancarlo extension proved better, the tests would have to include a search string where many positions has a $N_i>0$, that is, many substrings that match the suffix, as well as a text that also often matched a suffix of the string. An example where this could occur often is in settings with a small alphabet and long queries, such as in searching for substrings in DNA base pairs. 

When comparing Index10.0 (KMP) to Index10.1 (Boyer-Moore), it is seen that they perform very similarly in figure \ref{fig:Searchtimefulltext10}. However, when the length of the query grows, Index10.1 performs much better. This tendency is seen in figure \ref{fig:Searchtimefulltext10long}. This is due to the fact that the Boyer-Moore algorithm can skip larger potions of the search text. This figure also shows how the Apostolico-Giancarlo extension performs almost as well as Boyer-Moore but slightly worse. 

Looking at figure \ref{fig:Searchtimefulltext11}, the search times for the two Index11s are shown. This illustrates the difference between simply calculating the article intersection (Index11.0) and then searching linearly with Boyer-Moore (Index11.1). As observed, Index11.0 runs with a very good complexity as a function of the input file, as it is $O(q\cdot a)$ and therefore just proportional to the number of articles instead of their contents. 

Comparing the search times of Index11.1 to Index10.1 which both use the regular Boyer-Moore algorithm, the effectiveness of the triples method is clearly visible. Index11.1 searches for 1000 queries of five words in the order of 0.1-1 s, whereas Index10.1 uses on the order of 100-1000 s. Since the string matching algorithm is the same, this shows how many articles that the triples method can avoid to search through, yielding a time difference on the order of 100 times. 

Further investigating this difference between Index10 and Index11 is up to further work. It is interesting to see how many false positives that Index11.0's Fuzzy search gives compared to the exact answer that the other indices give. Furthermore, computing the average length of the article intersection in both the single and triple variant would hopefully match the observed difference between Index10.1 and 11.1. 

Looking at the indexing times shown in figure \ref{fig:IndexingAll}, several things can be said. Firstly, the difference between Index10.0 and the rest of the indices show the time spent creating the individual files for each article. This is because the rest of the indexing part of Index10.0 is identical to Index8. It is known that operating with computer memory and writing to the disk are some of the slowest operations that can be performed from a computational point of view, which is what the indexing time of Index10.0 shows. A simple work-around solution could be to write the individual files once and thus only write to the disk if the files have not been created. Another possible solution to the problem of having to go back to the article could be to only store the starting position of each article in the input file as a whole (e.g. that article no 4 begins at line 194) so that only a constant is stored per article in the indexing step and that in the search step, only the single input file has to be read instead of the many individual article files. 

Another noteworthy point regarding figure \ref{fig:IndexingAll} is the difference between Index11 and Index10. They both do the same work in terms of writing to the disk, but Index11 uses around twice as much time. A possible explanation is how the Hash function in Rust works. Because Index11 hashes triples of words (as a tuple) instead of a single word at a time, which firstly results in more unique keys in the table, but more importantly results in longer inputs for the hash function. Rust uses the hash function SipHash, which is described in \cite{Siphash}. Being a cryptographic hash function, it is made to provide security against hash-flooding denial-of-service attack (HashDoS) and have general robustness in these cases, but it is known to be slower than popular non-cryptographic hash functions that other languages and applications might use. Since it is described as linear in terms of the input\cite{Siphash} and the triples of strings in Index11 is on average 3 times as long as one string, this uses more time on hashing than previous indices. It is even possible that the hash function is naturally good at hashing strings but tuples of strings are less efficient, however this has not been tested. 

