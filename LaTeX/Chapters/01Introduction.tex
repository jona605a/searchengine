\chapter{Introduction}
Search engines are an essential part of our online experience. They help us to find relevant information quickly and easily, whether it's for work, study, or entertainment. 

Two straightforward approaches to building search engines are using linked lists and hash functions. However, when working with a large dataset, managing and searching for data can be even more challenging to do efficiently. 

In this context, the focus is on building a search engine for a large dataset consisting of a snapshot of Wikipedia from 2010, which has been converted into a simple text format. The goal is to support queries such as "which documents contain the word X" while compactly representing the dataset and supporting fast searches. The techniques used in this project apply to any large dataset, not just Wikipedia.

To accomplish this goal, the project will explore and implement advanced data structures and algorithms for indexing and searching through the dataset. The use of linked lists or hash functions is just the starting point. The project will include additional ... to ensure that the search engine can efficiently handle queries over a massive amount of data. Furthermore features to ... will be implemented. 

Overall, this project is an excellent opportunity to learn about the challenges of managing and searching large datasets and the advanced data structures and algorithms required to address them. Through building a search engine around the Wikipedia dataset, this project will offer a comprehensive understanding of search engines' inner workings, applicable to any data set.
